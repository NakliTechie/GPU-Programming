// Mental Model 12.0

// ... Host code ...

// ===================================
// Device (GPU) Code
// ===================================
__global__ void my_data_dependent_kernel(...) {
  
  // 1. A thread's work is based on its ID
  int my_output_start_index = threadIdx.x * WORK_PER_THREAD;
  
  // 2. **CRITICAL STEP**: The thread inspects the global input data
  //    to determine its INPUT range. This is often a search.
  int my_input_start_A = find_start_in_A(my_output_start_index);
  int my_input_start_B = find_start_in_B(my_output_start_index);
  // (and find end indices...)
  
  // 3. The thread now has its own independent sub-problem.
  //    It can work on this sub-problem sequentially.
  process_subproblem(&A[my_input_start_A], &B[my_input_start_B], &C[my_output_start_index]);
}